{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib import pyplot as plt, cm, colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.despine()\n",
    "from matplotlib import pyplot as plt, cm, colors\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import glob\n",
    "import os.path as ospath\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from sys import executable\n",
    "from subprocess import check_output\n",
    "from PyQt5.QtWidgets import QFileDialog, QApplication\n",
    "from IPython.display import HTML\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.spatial import distance\n",
    "from scipy import linalg\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "from picasso.picasso import io\n",
    "from picasso.picasso.postprocess import link, compute_dark_times\n",
    "from picasso.picasso.render import render\n",
    "from picasso.picasso.gui.render import estimate_kinetic_rate, fit_cum_exp\n",
    "from picasso.picasso.lib import append_to_rec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# define visualization options \n",
    "%matplotlib inline\n",
    "%gui qt\n",
    "\n",
    "# define colors:\n",
    "blue = \"#4C72B0\"\n",
    "orange = \"#DD8452\"\n",
    "red = \"#C44E52\"\n",
    "gray = \"#90A8CE\"\n",
    "\n",
    "\n",
    "def OpenFileDialog():\n",
    "    file = check_output([executable, __file__])\n",
    "    return file.strip()\n",
    "\n",
    "\n",
    "def gui_fname(dir=None):\n",
    "    \"\"\"\n",
    "    Select a file via a dialog and return the file name.\n",
    "    \"\"\"\n",
    "    if dir is None: \n",
    "        dir =\"./\"\n",
    "\n",
    "    app = QApplication([dir])\n",
    "    fname = QFileDialog.getExistingDirectory(None, \"Select a folder...\", \n",
    "            dir)\n",
    "    if isinstance(fname, tuple):\n",
    "        return fname[0]\n",
    "    else: \n",
    "        return str(fname)\n",
    "\n",
    "\n",
    "def load_files(dirname):\n",
    "    \n",
    "    os.chdir(dirname)\n",
    "    files = glob.glob(\"*.hdf5\")\n",
    "    \n",
    "    if files:\n",
    "        print(\"{} HDF5 files found.\".format(len(files)))\n",
    "    else:\n",
    "        print(\"No HDF5 files found at: {}\".format(dirname))\n",
    "            \n",
    "    return files\n",
    "\n",
    "\n",
    "def load_ring_data_df(dirname, filename):\n",
    "    file = ospath.join(dirname, filename)\n",
    "\n",
    "    try: \n",
    "        df = pd.read_pickle(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No results of previously analyzed datasets were detected.\")\n",
    "        return None\n",
    "    else: \n",
    "        print(\"Results of previously analyzed datasets were detected.\")\n",
    "        return df\n",
    "        \n",
    "\n",
    "def identify_new_files(files, df_ring_data):\n",
    "    \"\"\"\n",
    "    Identify which files have already been analyzed previously. \n",
    "    Return list of new files for processing\n",
    "    \"\"\"\n",
    "    new_files = []\n",
    "    for file in files:\n",
    "        if file not in df_ring_data['filename'].values:\n",
    "            new_files.append(file)\n",
    "    \n",
    "    n_old = len(files)-len(new_files)\n",
    "    n_new = len(new_files)\n",
    "    if n_old == 1:\n",
    "        print(\" {} HDF5 file was previously analyzed.\".format(n_old))\n",
    "    else: \n",
    "        print(\" {} HDF5 files were previously analyzed.\".format(n_old))\n",
    "        \n",
    "    if n_new == 1:\n",
    "        print(\" {} HDF5 file is new and will be analyzed.\".format(n_new))\n",
    "    else: \n",
    "        print(\" {} HDF5 files are new and will be analyzed.\".format(n_new))\n",
    "        \n",
    "    return new_files\n",
    "   \n",
    "\n",
    "def identify_fov_cell_type(df_ring_data, filenames, fov_id_start):\n",
    "    \"\"\"\n",
    "    For each file identify \n",
    "    - cell type: sporulating or vegetative cells\n",
    "    - fov index: fov from which the picks were generated\n",
    "    Results will be saved in a dataframe with columns:\n",
    "    'fov_id', 'filename', 'cell_type'\n",
    "    \n",
    "    If some files have been analyzed before the current script execution \n",
    "    the results were saved in the ring_data file and loaded to df_ring_data.\n",
    "    (columns: \"fov_id\", \"cell_type\", \"filename\", \"group\", ... where \n",
    "    group are the pick ids.)\n",
    "    If no prior analysis results exist, then df_ring_data = None. \n",
    "    Therefore we can check if a new file belongs to a previously analyzed fov.\n",
    "    \n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "    filenames_no_cell_type = []\n",
    "    \n",
    "    fov_id_counter = fov_id_start + 1\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "        # cell type: spor or veg:\n",
    "        cell_type = np.nan\n",
    "                \n",
    "        spor_found = re.search('spor', filename, re.IGNORECASE)\n",
    "        veg_found = re.search('veg', filename, re.IGNORECASE)\n",
    "        \n",
    "        if spor_found and not veg_found:\n",
    "            cell_type = 'spor'\n",
    "        elif not spor_found and veg_found:\n",
    "            cell_type = 'veg'\n",
    "        elif spor_found and veg_found:\n",
    "            # consider the string occuring first as cell type determining string\n",
    "            spor_found_location = spor_found.start()\n",
    "            veg_found_location = veg_found.start()\n",
    "            \n",
    "            if spor_found_location < veg_found_location:\n",
    "                cell_type = 'spor'\n",
    "            else:\n",
    "                cell_type = 'veg'\n",
    "        else:\n",
    "            cell_type = np.nan\n",
    "            filenames_no_cell_type.append(filename)\n",
    "            \n",
    "\n",
    "        \n",
    "        # search if a file from the same fov was already registered:\n",
    "        if not pd.isnull(cell_type):\n",
    "            # get substrings of filename that do not contain the cell_type string.\n",
    "            filename_substrings = re.split(cell_type, filename, flags = re.IGNORECASE)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # check if an already registered file exists that contains the substrings\n",
    "            filenames_found = []\n",
    "            old_or_new_file = [] # True if file from previous run of the script, False if new file.\n",
    "            for filename2 in dictionary.keys(): # search in files that were already registered.\n",
    "                contained = all([substring in filename2 for substring in filename_substrings])\n",
    "                if contained and filename != filename2:\n",
    "                    filenames_found.append(filename2)\n",
    "                    old_or_new_file.append(False)\n",
    "            if isinstance(df_ring_data, pd.DataFrame):\n",
    "                previously_analyzed_files = np.unique(df_ring_data['filename'])\n",
    "                for filename2 in previously_analyzed_files:\n",
    "                    contained = all([substring in filename2 for substring in filename_substrings])\n",
    "                    if contained and filename != filename2:\n",
    "                        filenames_found.append(filename2)\n",
    "                        old_or_new_file.append(True)\n",
    "            \n",
    "            # if one other file was found: assign the existing fov index to the newly registred file\n",
    "            # if no other file was found: assign a new fov index to the newly registered file\n",
    "            if len(filenames_found) > 1:\n",
    "                raise Exception('''Files from the same FOV than ''' + filename + ''' where searched. \n",
    "                However more than one other file was detected: \n",
    "                ''' + '\\n'.join(filenames_found))\n",
    "            elif len(filenames_found) == 1:\n",
    "                filename_found = filenames_found[0]\n",
    "                if old_or_new_file[0]: # filename_found is from previous run of the script\n",
    "                    fov_id = df_ring_data.loc[df_ring_data['filename'] == filename_found, 'fov_id'].iloc[0]\n",
    "                if not old_or_new_file[0]: # filename_found is also a new file.\n",
    "                    fov_id = dictionary[filename_found][0]\n",
    "            else: # No file from the same fov previously registered\n",
    "                fov_id = fov_id_counter\n",
    "                fov_id_counter += 1\n",
    "        \n",
    "        else:\n",
    "            fov_id = np.nan\n",
    "            \n",
    "        dictionary[filename] = [fov_id, filename, cell_type]\n",
    "        \n",
    "    df_results = pd.DataFrame.from_dict(dictionary, orient = 'index', columns = ['fov_id', 'filename', 'cell_type'])\n",
    "    df_results = df_results.reset_index()\n",
    "\n",
    "    print()\n",
    "    print('The cell type (spr or veg) of these files could not be determined')\n",
    "    print('and thus cannot be used for further analysis:')\n",
    "    for filename in filenames_no_cell_type:\n",
    "        print(' -', filename)\n",
    "        \n",
    "    return df_results\n",
    "                \n",
    "    \n",
    "\n",
    "def load_data(path):\n",
    "\n",
    "    try:\n",
    "        locs, info = io.load_locs(path)\n",
    "    #except io.NoMetadataFileError:\n",
    "    except:\n",
    "        return None, None, None\n",
    "    \n",
    "    try:\n",
    "        pixelsize = info[1][\"Pixelsize\"]\n",
    "    except:  \n",
    "        print(\"No pixelsize found in yaml file. Default 130 nm used.\")\n",
    "  \n",
    "    if hasattr(locs, \"x_pick_rot\"):\n",
    "\n",
    "        # convert px to nm\n",
    "        locs.x *= pixelsize\n",
    "        locs.y *= pixelsize\n",
    "        locs.x_pick_rot *= pixelsize\n",
    "        locs.y_pick_rot *= pixelsize\n",
    "        \n",
    "        return locs, info, pixelsize\n",
    "    else:\n",
    "        print('x_pick_rot column is missing!')\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def double_gaus(x,a,x0,sigma, b, x1, sigma1):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2)) + b*np.exp(-(x-x1)**2/(2*sigma1**2))\n",
    "\n",
    "def gaus(x,a,x0,sigma,y0):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2)) + y0\n",
    "\n",
    "def histogram(data, binning=100, column = \"y\"):\n",
    "    # histogram\n",
    "    n, bins = np.histogram(data[column], bins=binning)\n",
    "    centers = (bins[:-1] + bins[1:]) / 2\n",
    "    hist_data = [n, centers]\n",
    "    return hist_data\n",
    "\n",
    "def fit_peaks(data, p0, binning=100, column = \"y\", hist_data = None):\n",
    "    if hist_data is None:\n",
    "        hist_data = histogram(data, binning, column)\n",
    "    \n",
    "    n = hist_data[0]\n",
    "    centers = hist_data[1]\n",
    "    \n",
    "    p_fit, p_cov = optimize.curve_fit(gaus, centers, n, p0=p0)\n",
    "    p_fit[2] = np.abs(p_fit[2])\n",
    "    \"\"\"\n",
    "    try:\n",
    "        p_fit, p_cov = optimize.curve_fit(gaus, bins, n, p0=p0)\n",
    "        p_fit[2] = np.abs(p_fit[2])\n",
    "    except:\n",
    "        p_fit = [0,0,0]\n",
    "    \"\"\"\n",
    "    return p_fit, hist_data\n",
    "    \n",
    "\n",
    "def find_peaks(data, binning=100, axes=\"y\"):\n",
    "    \n",
    "    if axes == \"y\":\n",
    "        column = \"y_pick_rot\"\n",
    "    elif axes == \"x\":\n",
    "        column = \"x_pick_rot\"\n",
    "    elif axes == \"xyz\":\n",
    "        column = 2\n",
    "    \n",
    "    # find peak\n",
    "    bandwidth = estimate_bandwidth(data[column].reshape(-1, 1), quantile=0.2, n_samples=binning)\n",
    "    #print(\"estimated bandwidth: \"+str(bandwidth))\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(data[column].reshape(-1, 1))\n",
    "    labels = ms.labels_\n",
    "   # print(ms.cluster_centers_[0:2])\n",
    "    peaks = np.sort(ms.cluster_centers_[0:2], axis=None)\n",
    "    peak1 = float(ms.cluster_centers_[0])\n",
    "    estimated_peaks = {0:peak1}\n",
    "    \n",
    "    # fit peaks\n",
    "    p0 = [peak1/2, peak1, 40]\n",
    "    \n",
    "    p_fit, hist_data = fit_peaks(data, p0, binning=100, column = column)\n",
    "    \"\"\"\n",
    "    # histogram\n",
    "    n, bins = np.histogram(data[column], bins=binning)\n",
    "    bins = bins[1:]\n",
    "    hist_data = [n, bins]\n",
    "\n",
    "    # fit peaks\n",
    "    p0 = [peak1/2, peak1, 40]\n",
    "    try:\n",
    "        p_fit, p_cov = optimize.curve_fit(gaus, bins, n, p0=p0)\n",
    "    except:\n",
    "        p_fit = [0,0,0]\n",
    "    \"\"\" \n",
    "    \n",
    "    # check order of fitted peaks (peak 1 < peak 2)\n",
    "    #if p_fit[1] > p_fit[4]:\n",
    "    #    p_temp = p_fit.copy()\n",
    "    #    p_fit[0:3]=p_temp[3:6]\n",
    "    #    p_fit[3:6]=p_temp[0:3]\n",
    "       \n",
    "        \n",
    "    # p_fit: amplitued_1, center_1, width_1, amplitude_2, center_2, width_2\n",
    "        \n",
    "    return estimated_peaks, p_fit, hist_data\n",
    "\n",
    "\n",
    "def plot_peak_dist(data, hist_data, peaks, p_fit, binning=100,cutoff=1, axes=\"y\", title = None, ax=None):\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    \n",
    "    if axes == \"xyz\":\n",
    "        column == 1\n",
    "    \n",
    "    column = axes\n",
    "        \n",
    "    peak1 = peaks[0]\n",
    "\n",
    "    n = hist_data[0]\n",
    "    bins = hist_data[1]\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(9, 5))\n",
    "    binwidth = (max(bins)-min(bins)) / binning/2\n",
    "    ax.bar(bins, n, width=binwidth, color=gray)\n",
    "    xlin = np.linspace(0, data[column].max(), 1000)\n",
    "    ax.plot(xlin, gaus(xlin,*p_fit[0:3]), c=red, linewidth=2)\n",
    "    ax.axvline(p_fit[1]-(p_fit[2]*cutoff),c=blue, linewidth=2, linestyle=\"--\")\n",
    "    ax.axvline(p_fit[1]+(p_fit[2]*cutoff),c=blue, linewidth=2, linestyle=\"--\")\n",
    "    if title is None:\n",
    "        ax.set_title(\"Line profile\",loc=\"left\",fontsize=14)\n",
    "    else:\n",
    "        ax.set_title(title,loc=\"left\",fontsize=14)\n",
    "        \n",
    "    ax.set_xlabel(\"y (nm)\")\n",
    "    ax.set_ylabel(\"Counts\")  \n",
    "    ax.text(0.15,\n",
    "            0.7,\n",
    "            (\"Estimated Peaks:\\n\"\n",
    "            \"Peak at {:.1f} nm\\n\"\n",
    "            \"Fitted Peaks:\\n\"\n",
    "            \"Peak at {:.1f} nm\\n\"\n",
    "            \"sigma of {:.1f} nm\\n\").format(peak1, p_fit[1], p_fit[2]),\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"center\",\n",
    "            transform = ax.transAxes,\n",
    "            fontsize=12)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def isolate_ring(data, c, w, axes=\"y\", cutoff=1.0):\n",
    "    column = axes\n",
    "    ring_data = data[np.where((data[column]>(c-(cutoff*w))) & (data[column] <(c+(cutoff*w))))]\n",
    "    return ring_data\n",
    "\n",
    "\n",
    "def rodrigues_rot(P, n0, n1):\n",
    "    # adapted from https://meshlogic.github.io/posts/jupyter/curve-fitting/fitting-a-circle-to-cluster-of-3d-points/\n",
    "    # If P is only 1d array (coords of single point), fix it to be matrix\n",
    "    if P.ndim == 1:\n",
    "        P = P[np.newaxis,:]\n",
    "    \n",
    "    # Get vector of rotation k and angle theta\n",
    "    n0 = n0/linalg.norm(n0)\n",
    "    n1 = n1/linalg.norm(n1)\n",
    "    k = np.cross(n0,n1)\n",
    "    k = k/linalg.norm(k)\n",
    "    theta =np.arccos(np.dot(n0,n1))\n",
    "    \n",
    "    # Compute rotated points\n",
    "    P_rot = np.zeros((len(P),3))\n",
    "    for i in range(len(P)):\n",
    "        P_rot[i] = P[i]*np.cos(theta) + np.cross(k,P[i])*np.sin(theta) + k*np.dot(k,P[i])*(1-np.cos(theta))\n",
    "\n",
    "    return P_rot\n",
    "\n",
    "\n",
    "def rotate_ring(XYZ): \n",
    "    # Fitting plane by SVD for the mean-centered data\n",
    "    # Eq. of plane is <p,n> + d = 0, where p is a point on plane and n is normal vector\n",
    "       \n",
    "    # Normal vector of fitting plane is given by 3rd column in V\n",
    "    # Note linalg.svd returns V^T, so we need to select 3rd row from V^T\n",
    "    ring_mean = XYZ.mean(axis=0)\n",
    "    ring_centered = XYZ - ring_mean\n",
    "    U,s,V = linalg.svd(ring_centered)\n",
    "    normal = V[2,:]\n",
    "    d = -np.dot(ring_mean, normal) \n",
    "        \n",
    "    n0 = normal # new z axes\n",
    "    n1 = [0,0,1] # old z axes\n",
    "\n",
    "    ring_rot = rodrigues_rot(ring_centered, n0, n1)\n",
    "    \n",
    "    return ring_rot, normal\n",
    "\n",
    "\n",
    "def plot_3d_ring(ring_rot, dist, ax=None):\n",
    "    \n",
    "    ax.scatter(ring_rot.x, ring_rot.y, ring_rot.z-dist/2,c=blue, label=\"FtsZ\", alpha=0.5)\n",
    "    #ax.scatter(ring_rot[1][:,0], ring_rot[1][:,1], ring_rot[1][:,2]+dist/2,c=orange,label=\"Mother\", alpha=0.5)\n",
    "    ax.set_xlabel(\"x (nm)\")\n",
    "    ax.set_ylabel(\"y (nm)\")\n",
    "    ax.set_zlabel(\"z (nm)\")\n",
    "    ax.legend(loc=\"best\",labelspacing=0.1)\n",
    "    #ax.view_init(elev=2., azim=10.)\n",
    "    ax.view_init(elev=30., azim=10.)\n",
    "    set_axes_equal_3d(ax)\n",
    "\n",
    "    return ax\n",
    "    \n",
    "    \n",
    "def set_axes_equal_3d(ax):\n",
    "    limits = np.array([ax.get_xlim3d(), ax.get_ylim3d(), ax.get_zlim3d()])\n",
    "    spans = abs(limits[:,0] - limits[:,1])\n",
    "    centers = np.mean(limits, axis=1)\n",
    "    radius = 0.5 * max(spans)\n",
    "    ax.set_xlim3d([centers[0]-radius, centers[0]+radius])\n",
    "    ax.set_ylim3d([centers[1]-radius, centers[1]+radius])\n",
    "    ax.set_zlim3d([centers[2]-radius, centers[2]+radius])\n",
    "    \n",
    "\n",
    "def angle_between(u, v, n=None):\n",
    "    if n is None:\n",
    "        return np.arctan2(np.linalg.norm(np.cross(u,v)), np.dot(u,v))*180/np.pi\n",
    "    else:\n",
    "        return np.arctan2(np.dot(n,np.cross(u,v)), np.dot(u,v))*180/np.pi\n",
    "\n",
    "\n",
    "def calc_R(x, y, xc, yc):\n",
    "    # adapted from https://gist.github.com/lorenzoriano/6799568\n",
    "    \"\"\" calculate the distance of each 2D points from the center (xc, yc) \"\"\"\n",
    "    return np.sqrt((x-xc)**2 + (y-yc)**2)\n",
    "\n",
    "\n",
    "def f(c, x, y):\n",
    "    \"\"\" calculate the algebraic distance between the data points and the mean circle centered at c=(xc, yc) \"\"\"\n",
    "    Ri = calc_R(x, y, *c)\n",
    "    return Ri - np.median(Ri)\n",
    "\n",
    "\n",
    "def leastsq_circle(x,y):\n",
    "    \n",
    "    x_m = np.median(x)\n",
    "    y_m = np.median(y)\n",
    "    center_estimate = x_m, y_m\n",
    "    center, ier = optimize.leastsq(f, center_estimate, args=(x,y))\n",
    "    xc, yc = center\n",
    "    Ri       = calc_R(x, y, *center)\n",
    "    R        = np.median(Ri)\n",
    "    residu   = np.sum((Ri - R)**2)\n",
    "    return xc, yc, Ri, R, residu\n",
    "\n",
    "\n",
    "def plot_data_circle(x, y, xc, yc, R, residu_norm, id, center=True, ax=None):\n",
    "    \n",
    "    if id == 0:\n",
    "        label = \"FtsZ\"\n",
    "        color = blue\n",
    "    else:\n",
    "        label = \"mother\"\n",
    "        color = orange\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    if center:\n",
    "        x -= xc\n",
    "        y -= yc\n",
    "        xc = 0\n",
    "        yc = 0 \n",
    "        \n",
    "    #f, ax = plt.subplots(figsize=(5,5))  #figsize=(7, 5.4), dpi=72,\n",
    "    theta_fit = np.linspace(-np.pi,np.pi, 180)\n",
    "    x_fit = xc + R*np.cos(theta_fit)\n",
    "    y_fit = yc + R*np.sin(theta_fit)\n",
    "    \n",
    "    # plot fit\n",
    "    ax.plot(x_fit, y_fit, label=\"Fitted circle\", lw=2, c=red)\n",
    "    ax.plot([xc], [yc], mec=\"y\", mew=1,  c=red)\n",
    "    \n",
    "    # plot data\n",
    "    ax.scatter(x, y, alpha=0.4,  label=\"Projected locs\", marker=\".\", c=color)\n",
    "    \n",
    "    ax.set_xlabel(\"y rotated (nm)\")\n",
    "    ax.set_ylabel(\"z rotated (nm)\")\n",
    "    #ax.axis(\"equal\")\n",
    "    ax.set_xlim([-800,800])\n",
    "    ax.set_aspect(\"equal\",adjustable=\"datalim\")\n",
    "    \n",
    "    ax.legend(loc=\"best\", labelspacing=0.1)\n",
    "    \"\"\"\n",
    "    ax.set_title(\"Least squares circle {}\\n\"\n",
    "                 \"Fit radius: {:.1f} nm\\n\"\n",
    "                 \"Mean of the |resdiual| values: {:.1f} nm\".format(label,R,residu_norm),loc=\"left\",fontsize=14)\n",
    "    \"\"\"\n",
    "    ax.set_title(\"Least squares circle {}\\n\"\n",
    "                 \"Fit radius: {:.1f} nm\".format(label,R),loc=\"left\",fontsize=14)\n",
    "    \n",
    "    \n",
    "    return \n",
    "\n",
    "def polar_coordinate_angle(x_c, y_c, x, y):\n",
    "    \"\"\"\n",
    "    x_center, y_center: center coordinate from ring fit.\n",
    "    x,y: arrays saving coordinates of localizations.\n",
    "    \"\"\"\n",
    "    xx = x-x_c # x coordinates with x_center as 0\n",
    "    yy = y-y_c # x coordinates with x_center as 0\n",
    "\n",
    "    angles = np.degrees(np.arctan2(yy,xx))\n",
    "\n",
    "    return angles\n",
    "\n",
    "def check_consistency(ring_par):\n",
    "    \n",
    "#    ev = 0\n",
    "\n",
    "#    amp_1, c_1, w_1 = ring_par[0]\n",
    "#    amp_2, c_2, w_2 = ring_par[1]\n",
    "\n",
    "#    if amp_1/amp_2 >= 0.3 and amp_2/amp_1 >= 0.3:\n",
    "#        ev +=1 \n",
    "\n",
    "#    if abs(c_1-c_2) > 30 and abs(c_1-c_2) < 300:\n",
    "#        ev +=1\n",
    "\n",
    "#    if w_1/w_2 >= 0.3 and w_2/w_1 >=0.3:\n",
    "#        ev +=1\n",
    "        \n",
    "    return (True)\n",
    "\n",
    "def plot_cum_exp(pooled_locs, fit_result_len, fit_result_dark, id, ax=None):\n",
    "    \n",
    "    if id == 0:\n",
    "        color = blue\n",
    "        label = 'FtsZ'\n",
    "    if id == 1:\n",
    "        color = orange\n",
    "        label = 'mother'\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    data = pooled_locs.dark\n",
    "    data.sort()\n",
    "    y = np.arange(1, len(data) + 1)\n",
    "       \n",
    "    a = fit_result_dark.best_values[\"a\"]\n",
    "    t = fit_result_dark.best_values[\"t\"]\n",
    "    c = fit_result_dark.best_values[\"c\"]\n",
    "\n",
    "    ax.set_title(\n",
    "        \"Dark time (cumulative) {}\\n\"\n",
    "        r\"$Fit: {:.2f}\\cdot(1-exp(x/{:.2f}))+{:.2f}$\".format(label, a, t, c),loc=\"left\",fontsize=14)\n",
    "    data = pooled_locs.dark\n",
    "    data.sort()\n",
    "    y = np.arange(1, len(data) + 1)\n",
    "\n",
    "    ax.semilogx(data, y, c=color, label=\"Data\")\n",
    "    ax.semilogx(data, fit_result_dark.best_fit, c=red, label=\"Fit\")\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_xlabel(\"Duration (frames)\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    \n",
    "    return ax\n",
    "\n",
    "\n",
    "def save_ring_locs(locs, info, path, fov_id, cell_type, pick, id, link=False, filename = ''):\n",
    "    \n",
    "    if link:\n",
    "        ending = \"_link.hdf5\"\n",
    "    else:\n",
    "        ending = \".hdf5\"\n",
    "    \n",
    "    if filename != '':\n",
    "        ending = filename + ending\n",
    "       \n",
    "    locs.x /= 130\n",
    "    locs.y /= 130\n",
    "    \n",
    "    if np.isnan(id):\n",
    "        locs_name =  \"fov_{}_{}_pick_{}{}\".format(fov_id, cell_type, pick, ending)\n",
    "    else:\n",
    "        locs_name =  \"fov_{}_{}_pick_{}_ring_{}{}\".format(fov_id, cell_type, pick, id, ending)\n",
    "    locs_path = os.path.join(path,\"ring_locs\")\n",
    "    locs_path_name = os.path.join(locs_path, locs_name)\n",
    "    \n",
    "    if not os.path.isdir(locs_path):\n",
    "        os.makedirs(locs_path, exist_ok=True)\n",
    "\n",
    "    \n",
    "    io.save_locs(locs_path_name, locs, info)\n",
    "\n",
    "def export_pick_img(locs, path, fov_id, cell_type, pick, id, link=False):\n",
    "    \n",
    "    if link:\n",
    "        ending = \"_link.png\"\n",
    "    else:\n",
    "        ending = \".png\"\n",
    "    \n",
    "    pixelsize = 130\n",
    "\n",
    "    export_locs = locs.copy()\n",
    "    \n",
    "    export_locs.x /= pixelsize\n",
    "    export_locs.y /= pixelsize\n",
    "    \n",
    "    x_min = np.min(export_locs.x)    \n",
    "    x_max = np.max(export_locs.x)\n",
    "    y_min = np.min(export_locs.y)\n",
    "    y_max = np.max(export_locs.y)\n",
    "\n",
    "    viewport =  (y_min, x_min), (y_max, x_max)\n",
    "    oversampling = 50\n",
    "    len_x, image = render(export_locs, viewport = viewport, oversampling=oversampling, blur_method=\"smooth\")\n",
    "    \n",
    "    img_name = \"fov_{}_{}_pick_{}_ring_{}{}\".format(fov_id, cell_type, pick, id, ending)\n",
    "    img_path = os.path.join(path,\"ring_images\")\n",
    "    img_path_name = os.path.join(img_path,img_name)\n",
    "    \n",
    "    if not os.path.isdir(img_path):\n",
    "        os.makedirs(img_path)\n",
    "    \n",
    "    plt.imsave(img_path_name, image, cmap=\"hot\")\n",
    "\n",
    "\n",
    "def plot_locs_z_colormap(data, axes, title, fig, ax):\n",
    "\n",
    "    # Generate data...\n",
    "    if axes == \"y_pick_rot\":\n",
    "        x = data.y_pick_rot\n",
    "        y = data.x_pick_rot\n",
    "        z = data.z\n",
    "        ax.set_ylabel(\"x (nm)\")\n",
    "        ax.set_xlabel(\"y (nm)\") \n",
    "    elif axes == \"y\":\n",
    "        x = data.y\n",
    "        y = data.x\n",
    "        z = data.z\n",
    "        ax.set_ylabel(\"x (nm)\")\n",
    "        ax.set_xlabel(\"y (nm)\") \n",
    "    elif axes == \"x_pick_rot\":\n",
    "        x = data.x_pick_rot\n",
    "        y = data.y_pick_rot\n",
    "        z = data.z\n",
    "        ax.set_xlabel(\"x (nm)\")\n",
    "        ax.set_ylabel(\"y (nm)\")\n",
    "    elif axes == \"x\":\n",
    "        x = data.x\n",
    "        y = data.y\n",
    "        z = data.z\n",
    "        ax.set_xlabel(\"x (nm)\")\n",
    "        ax.set_ylabel(\"y (nm)\")  \n",
    "    \n",
    "    sc = ax.scatter(x, y, s = 10, c=z, cmap='jet')\n",
    "    fig.colorbar(sc, ax = ax)\n",
    "    \n",
    "    ax.set_aspect('equal', adjustable='datalim')\n",
    "\n",
    "    ax.set_title(title,loc=\"left\",fontsize=14)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def plot_locs_overlay(data1, data2, axes, ax, label1 = '', label2 = '', title = ''):\n",
    "\n",
    "    # Generate data...\n",
    "    if axes == \"y_pick_rot\":\n",
    "        x1 = data1.y_pick_rot\n",
    "        y1 = data1.x_pick_rot\n",
    "        z1 = data1.z\n",
    "        \n",
    "        x2 = data2.y_pick_rot\n",
    "        y2 = data2.x_pick_rot\n",
    "        z2 = data2.z\n",
    "        \n",
    "        ax.set_ylabel(\"x (nm)\")\n",
    "        ax.set_xlabel(\"y (nm)\")\n",
    "    elif axes == \"y\":\n",
    "        x1 = data1.y\n",
    "        y1 = data1.x\n",
    "        z1 = data1.z\n",
    "        \n",
    "        x2 = data2.y\n",
    "        y2 = data2.x\n",
    "        z2 = data2.z\n",
    "        \n",
    "        ax.set_ylabel(\"x (nm)\")\n",
    "        ax.set_xlabel(\"y (nm)\")\n",
    "    elif axes == \"x_pick_rot\":\n",
    "        x1 = data1.x_pick_rot\n",
    "        y1 = data1.y_pick_rot\n",
    "        z1 = data1.z\n",
    "        \n",
    "        x2 = data2.x_pick_rot\n",
    "        y2 = data2.y_pick_rot\n",
    "        z2 = data2.z\n",
    "    elif axes == \"x\":\n",
    "        x1 = data1.x\n",
    "        y1 = data1.y\n",
    "        z1 = data1.z\n",
    "        \n",
    "        x2 = data2.x\n",
    "        y2 = data2.y\n",
    "        z2 = data2.z\n",
    "    \n",
    "        ax.set_xlabel(\"x (nm)\")\n",
    "        ax.set_ylabel(\"y (nm)\")  \n",
    "    \n",
    "    ax.scatter(x1, y1, s = 10, c='red', label = label1)\n",
    "    ax.scatter(x2, y2, s = 10, c='blue', label = label2)\n",
    "    \n",
    "    ax.set_aspect('equal', adjustable='datalim')\n",
    "    \n",
    "    ax.set_title(title,loc=\"left\",fontsize=14)\n",
    "    \n",
    "    ax.legend()\n",
    "    \n",
    "    return ax\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 HDF5 files found.\n"
     ]
    }
   ],
   "source": [
    "#path = gui_fname()\n",
    "path = r'W:\\users\\reinhardt\\z.software\\Git\\spor-PAINT\\dev_sr\\spor-paint\\Long_pos_FtsZ'\n",
    "filenames_all = load_files(path)\n",
    "\n",
    "\n",
    "plotting = True\n",
    "max_dist = 130 #nanometer\n",
    "max_dark_time = 15 #frames\n",
    "# binning = 50 # binning for peak histogram\n",
    "binsize = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results of previously analyzed datasets were detected.\n",
      "\n",
      "The cell type (spr or veg) of these files could not be determined\n",
      "and thus cannot be used for further analysis:\n"
     ]
    }
   ],
   "source": [
    "# Check if some of the found hdf5 files were already analyzed?\n",
    "# If yes, open ring_data dataframe with previous results.\n",
    "df_ring_data = load_ring_data_df(path, \"ring_data.pkl\")\n",
    "\n",
    "\n",
    "# Identify which files have not yet been analyzed.\n",
    "if df_ring_data is not None:\n",
    "    filenames = identify_new_files(filenames_all, df_ring_data)\n",
    "    fov_id_start = df_ring_data['fov_id'].max()\n",
    "else:\n",
    "    filenames = filenames_all\n",
    "    fov_id_start = 0\n",
    "\n",
    "# Create a dictionary that saves which file was taken from which FOV and which cell types are contained (spor or veg)\n",
    "# {filename_1: (FOV_id, 'spor'), filename_2: (FOV_id, 'veg'), ...}\n",
    "df_fov_file_assign = identify_fov_cell_type(df_ring_data, filenames, fov_id_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOV ID: 1\n",
      "  spor : 230314_kcb300_spor_RBnb5xr2_200pm-r2_fov1_FtsZ_DP_1_drift_picked.hdf5\n",
      "  veg  : --\n",
      "FOV ID: 2\n",
      "  spor : 230314_kcb300_spor_RBnb5xr2_200pm-r2_fov3_FtsZ_DP_1_drift_picked.hdf5\n",
      "  veg  : --\n",
      "FOV ID: 3\n",
      "  spor : 230314_kcb300_spor_RBnb5xr2_200pm-r2_fov2_FtsZ_DP_1_drift_picked.hdf5\n",
      "  veg  : --\n"
     ]
    }
   ],
   "source": [
    "for fov_id in range(int(fov_id_start)+1, int(df_fov_file_assign['fov_id'].max())+1):\n",
    "    \n",
    "    print('FOV ID:', fov_id)\n",
    "    files_fov_id = df_fov_file_assign.loc[df_fov_file_assign['fov_id'] == fov_id]\n",
    "\n",
    "    \n",
    "    print('  spor : ', end = '')\n",
    "\n",
    "    spor_name = files_fov_id.loc[files_fov_id['cell_type'] == 'spor']['filename']\n",
    "    if spor_name.empty:\n",
    "        print('--')\n",
    "    else:\n",
    "        print(spor_name.iloc[0])\n",
    "\n",
    "    \n",
    "    print('  veg  : ', end = '')\n",
    "\n",
    "    veg_name = files_fov_id.loc[files_fov_id['cell_type'] == 'veg']['filename']\n",
    "    if veg_name.empty:\n",
    "        print('--')\n",
    "    else:\n",
    "        print(veg_name.iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8308efbf230546579bbb90839db3af45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "230314_kcb300_spor_RBnb5xr2_200pm-r2_fov1_FtsZ_DP_1_drift_picked.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6bd5d0bb4747988f6db0f8008bfbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing picks:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "230314_kcb300_spor_RBnb5xr2_200pm-r2_fov3_FtsZ_DP_1_drift_picked.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4a5c083d0b4d969098501a97eed564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing picks:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "230314_kcb300_spor_RBnb5xr2_200pm-r2_fov2_FtsZ_DP_1_drift_picked.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f828802ad90f430dbc7575623416bd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing picks:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following files could not be loaded.\n",
      "Probably they miss the x_pick_rot column:\n",
      "\n",
      "Calculation finished.\n",
      "Total: 47 rings analysed, 0 excluded.\n",
      "Data saved to CSV file in locs folder.\n"
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "# initialize containers\n",
    "ring_data = []\n",
    "ring_locs = {}\n",
    "ring_locs_linked = {}\n",
    "ring_kinetics = {}\n",
    "ring_kinetics_fit = {}\n",
    "ring_radii = {}\n",
    "ring_angles = {}\n",
    "center = {}\n",
    "\n",
    "rings_excluded = []\n",
    "ring_n_events = {}\n",
    "circle_plots = {}\n",
    "\n",
    "\n",
    "analysis_folder = os.path.join(path, \"analysis\")\n",
    "analysis_folder_excluded = os.path.join(analysis_folder, \"excluded\")\n",
    "\n",
    "# image export settings\n",
    "img_format = \".png\"\n",
    "dpi = 100\n",
    "\n",
    "# cutoff is mutliplied to the sigma of the peak fit for the seperation of the two rings\n",
    "# smaller cutoff means smaller ring sections\n",
    "cutoff = 1.5\n",
    "\n",
    "#prepare analysis folder\n",
    "if not os.path.isdir(analysis_folder):\n",
    "    os.makedirs(analysis_folder)\n",
    "if not os.path.isdir(analysis_folder_excluded):\n",
    "    os.makedirs(analysis_folder_excluded)\n",
    "\n",
    "files_no_x_pick_rot = []\n",
    "    \n",
    "#iterate over locs in directory:\n",
    "for filename in tqdm(filenames, desc=\"Processing files\"):\n",
    "\n",
    "    \n",
    "    print()\n",
    "    print(filename)\n",
    "    \n",
    "    \n",
    "    fov_id = df_fov_file_assign.loc[df_fov_file_assign['filename'] == filename]['fov_id'].iloc[0]\n",
    "    cell_type = df_fov_file_assign.loc[df_fov_file_assign['filename'] == filename]['cell_type'].iloc[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    if np.isnan(fov_id):\n",
    "        print('FOV ID is nan.')\n",
    "        continue\n",
    "    fov_id = int(fov_id)\n",
    "    \n",
    "    #load locs and convert distances from px to nm (Attention!)\n",
    "    locs, info, pixelsize = load_data(os.path.join(path,filename))\n",
    "    \n",
    "    if locs is None:\n",
    "        files_no_x_pick_rot.append(filename)\n",
    "        print(\"File {} not loaded.\".format(filename))\n",
    "        continue\n",
    "    \n",
    "    # iterate over picks in a file\n",
    "    for pick in tqdm(np.unique(locs.group), desc=\"Processing picks\"):\n",
    "     \n",
    "        # select locs from pick\n",
    "        pick_locs = locs[locs.group == pick]\n",
    "        \n",
    "        \n",
    "        # hist data\n",
    "        y_min = pick_locs['y_pick_rot'].min()\n",
    "        y_max = pick_locs['y_pick_rot'].max()\n",
    "        bins = np.arange(y_min, y_max+binsize, binsize)\n",
    "        hist_data = histogram(pick_locs, binning=bins, column = \"y_pick_rot\")\n",
    "        \n",
    "        # set up plot showing the bacterium with gridspec\n",
    "        fig = plt.figure(figsize=(17, 14) , constrained_layout=True) #\n",
    "        gs = fig.add_gridspec(2,1)\n",
    "        fig.suptitle((\"FOV {}, {}, Pick {} \\n\"\n",
    "                      \"File: {}\").format(fov_id, cell_type, pick, filename), \n",
    "                     fontsize=16, \n",
    "                     ha=\"center\")\n",
    "\n",
    "        \n",
    "        # plot scatter plot for locs in pick with z colorcode\n",
    "        ax2 = fig.add_subplot(gs[0, 0])\n",
    "        plot_locs_z_colormap(pick_locs, \n",
    "                             'y_pick_rot', \n",
    "                             title = 'Pick localizations',\n",
    "                             fig = fig, \n",
    "                             ax = ax2)\n",
    "\n",
    "        ax2.axes.set_aspect('equal')\n",
    "        \n",
    "        \n",
    "        # plot histogram for locs in pick\n",
    "        ax1 = fig.add_subplot(gs[1, 0], sharex=ax2)\n",
    "\n",
    "        \n",
    "        n = hist_data[0]\n",
    "        bins = hist_data[1]\n",
    "\n",
    "        #binsize = (max(bins)-min(bins)) / binning\n",
    "        ax1.bar(bins, n, width=binsize, color=gray)\n",
    "        ax1.set_title('Line profile',loc=\"left\",fontsize=14)\n",
    "\n",
    "        ax1.set_xlabel(\"y (nm)\")\n",
    "        ax1.set_ylabel(\"Counts\")\n",
    "        \n",
    "        # get first bin that from which on non of the next 10 bins is smaller than 10% median of non-zero bins\n",
    "        n_non_0 = n[n>0]\n",
    "        median = np.median(n_non_0)\n",
    "        # returns index of all eleements above 0.1 x median in the array n\n",
    "        idx_above = np.where(n>(0.1*median))[0]\n",
    "        \n",
    "        \n",
    "        for i in range(len(idx_above)-10):\n",
    "\n",
    "            # check if the following 10 elements are also above the 0.1 x median\n",
    "            # That's the case if the ten following elements in the idx_above list\n",
    "            # continuously increase by 1 in each eleemnt. \n",
    "            onset = idx_above[i]\n",
    "            onset_10 = idx_above[i+10]\n",
    "            if onset_10 - onset == 10:\n",
    "                break\n",
    "        \n",
    "        # get last bin before which none of the previous 10 bins is smaller than 10% median of non-zero bins\n",
    "        for i in reversed(range(10, len(idx_above))):\n",
    "\n",
    "            # check if the following 10 elements are also above the 0.1 x median\n",
    "            # That's the case if the ten following elements in the idx_above list\n",
    "            # continuously increase by 1 in each eleemnt. \n",
    "            offset = idx_above[i]\n",
    "            offset_10 = idx_above[i-10]\n",
    "            if offset - offset_10 == 10:\n",
    "                break\n",
    "        \n",
    "\n",
    "        bin_onset = bins[onset]-binsize/2 # bins contains the bin centers\n",
    "        bin_offset = bins[offset]+binsize/2 # bins contains the bin centers\n",
    "\n",
    "        ax2.axvline(bin_onset,c=blue, linewidth=2, linestyle=\"--\")\n",
    "        ax1.axvline(bin_onset,c=blue, linewidth=2, linestyle=\"--\")\n",
    "        \n",
    "        ax2.axvline(bin_offset,c=blue, linewidth=2, linestyle=\"--\")\n",
    "        ax1.axvline(bin_offset,c=blue, linewidth=2, linestyle=\"--\")\n",
    "        \n",
    "        ax1.axhline(0.1*median,c=orange, linewidth=2, linestyle=\"--\")\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        plot_peak_dist(pick_locs,\n",
    "                       hist_data,\n",
    "                       estimated_peaks,\n",
    "                       r_par,\n",
    "                       binning=binning,\n",
    "                       cutoff=cutoff,\n",
    "                       axes=\"y_pick_rot\",\n",
    "                       title=\"Line profile\",\n",
    "                       ax=ax1)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        ################\n",
    "        # (1) estimate the postition of the rings using a histogram along the pick direction\n",
    "        #  a ring should yield a gaussian peak (2D projection in XY)\n",
    "        ################\n",
    "        \n",
    "        #estimated_peaks, r_par, hist_data = find_peaks(pick_locs, binning=bins, axes=\"y\")\n",
    "        # estimated peaks are rough estimates of peak position from MeanShift analysis \n",
    "        # used to initialize guassian fits\n",
    "        # r_par yields an array containing: [amplitued_1, center_1, width_1, offset_1]\n",
    "        \n",
    "        p0 = [500, bins[np.argmax(n)], 50, median]\n",
    "        r_par, _ = fit_peaks(pick_locs, p0, hist_data = hist_data) #  binning=bins, column = \"y_pick_rot\", \n",
    "\n",
    "        # seperate ring parameter to the corresponding ring\n",
    "        ring_parameter = [] # to work as the double band script\n",
    "        ring_parameter.append(r_par)\n",
    "        \n",
    "        \n",
    "        xlin = np.linspace(0, pick_locs['y_pick_rot'].max(), 3000)\n",
    "        ax1.plot(xlin, gaus(xlin,*r_par), c=red, linewidth=2)\n",
    "        ax1.annotate('Ring position: {:.1f} nm\\n'\n",
    "                     'Sigma: {:.1f} nm'.format(r_par[1], r_par[2]), xy = (r_par[1] + 100, r_par[0]+r_par[3]) )\n",
    "        \n",
    "\n",
    "        ax1.axvline(r_par[1], c=red, linewidth=2, linestyle=\"--\")\n",
    "        ax2.axvline(r_par[1], c=red, linewidth=2, linestyle=\"--\")\n",
    "\n",
    "        # write down position of cell start and end\n",
    "        ax1.annotate('Cell start:\\n {:.1f} nm'.format(bin_onset), xy = (bin_onset + 10, r_par[0]+r_par[3]) )\n",
    "        ax1.annotate('Cell end:\\n {:.1f} nm'.format(bin_offset), xy = (bin_offset + 10, r_par[0]+r_par[3]) )\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        ################\n",
    "        # (5.2) append data into large array\n",
    "        ################\n",
    "\n",
    "        ring_data.append([fov_id, #running file index\n",
    "                          cell_type, # veg or spore\n",
    "                          filename, #filename\n",
    "                          pick, #pick number\n",
    "                          bin_onset, # cell start\n",
    "                          bin_offset, # cell end\n",
    "                          bin_offset-bin_onset, # cell length\n",
    "                          r_par[0], # ring peak amplitude\n",
    "                          r_par[1], # ring peak position\n",
    "                          r_par[2], # ring peak width\n",
    "                          r_par[3], # ring peak offset\n",
    "                          r_par[1]-bin_onset, # distance peak to cell start\n",
    "                          (r_par[1]-bin_onset)/(bin_offset-bin_onset) # position of peak in % of cell length\n",
    "                         ])\n",
    "        \n",
    "        \n",
    "        ################\n",
    "        # (6) save plots\n",
    "        ################\n",
    "\n",
    "\n",
    "        # ring analysis\n",
    "        img_fname = \"fov_{}_{}_pick_{}\".format(fov_id, cell_type, pick)\n",
    "        img_name = os.path.join(analysis_folder, img_fname)\n",
    "        fig.savefig(img_name+img_format, dpi=dpi, format=\"png\")\n",
    "        plt.close(fig)\n",
    "                    \n",
    "\n",
    "            \n",
    "            \n",
    "print()\n",
    "print('The following files could not be loaded.')\n",
    "print('Probably they miss the x_pick_rot column:')\n",
    "for filename in files_no_x_pick_rot:\n",
    "    print(' -', filename)\n",
    "\n",
    "print()\n",
    "print(\"Calculation finished.\")\n",
    "print(\"Total: {} rings analysed, {} excluded.\".format(len(ring_data), len(rings_excluded)))\n",
    "\n",
    "\n",
    "# Save ring data\n",
    "df_ring_data_add = pd.DataFrame(ring_data, columns=[\"fov_id\",\n",
    "                                                \"cell_type\",\n",
    "                                                \"filename\",\n",
    "                                                \"group\",\n",
    "                                                \"cell start\",\n",
    "                                                \"cell end\",\n",
    "                                                \"cell length\",\n",
    "                                                \"peak amplitude\",\n",
    "                                                \"peak position\",\n",
    "                                                \"peak sigma\",\n",
    "                                                \"peak offset\",\n",
    "                                                \"distance of peak to cell start\",\n",
    "                                                \"relative peak position in % of cell length\"\n",
    "                                               ])\n",
    "if df_ring_data is not None:\n",
    "    df_ring_data_save = pd.concat([df_ring_data, df_ring_data_add], ignore_index = True)\n",
    "else:\n",
    "    df_ring_data_save = df_ring_data_add\n",
    "    \n",
    "df_ring_data_save.to_csv(\"ring_data.csv\")        \n",
    "# Save dataframe with cell means for easy loading of data for postprocessing\n",
    "df_ring_data_save.to_pickle(\"ring_data.pkl\")\n",
    "\n",
    "\n",
    "print(\"Data saved to CSV file in locs folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following files could not be loaded.\n",
      "Probably they miss the x_pick_rot column:\n",
      "\n",
      "Calculation finished.\n",
      "Total: 0 rings analysed, 0 excluded.\n",
      "Data saved to CSV file in locs folder.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save analysis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'ring_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\8\\ipykernel_10060\\4174387211.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mdf_ring_data_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ring_data_add\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdf_ring_data_save\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ring_data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;31m# Save dataframe with cell means for easy loading of data for postprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mdf_ring_data_save\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ring_data.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\users\\reinhardt\\z.software\\PythonEnvironment\\envs\\spor_paint\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3480\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3481\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3482\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3483\u001b[0m         )\n\u001b[0;32m   3484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\users\\reinhardt\\z.software\\PythonEnvironment\\envs\\spor_paint\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\users\\reinhardt\\z.software\\PythonEnvironment\\envs\\spor_paint\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m         ) as handles:\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mZ:\\users\\reinhardt\\z.software\\PythonEnvironment\\envs\\spor_paint\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'ring_data.csv'"
     ]
    }
   ],
   "source": [
    "# todo: add normal vector\n",
    "df_ring_data_add = pd.DataFrame(ring_data, columns=[\"fov_id\",\n",
    "                                                \"cell_type\",\n",
    "                                                \"filename\",\n",
    "                                                \"group\",\n",
    "                                                \"residual\",\n",
    "                                                \"radius\",\n",
    "                                                \"angle_between_ring_and_coverslip\",\n",
    "                                                \"Sigma\",\n",
    "                                                \"n_events\",\n",
    "                                                \"mean_bright\",\n",
    "                                                \"mean_dark\",\n",
    "                                                \"fit_bright\",\n",
    "                                                \"fit_dark\",\n",
    "                                               ])\n",
    "if df_ring_data is not None:\n",
    "    df_ring_data_save = pd.concat([df_ring_data, df_ring_data_add], ignore_index = True)\n",
    "else:\n",
    "    df_ring_data_save = df_ring_data_add\n",
    "    \n",
    "df_ring_data_save.to_csv(\"ring_data.csv\")        \n",
    "# Save dataframe with cell means for easy loading of data for postprocessing\n",
    "df_ring_data_save.to_pickle(\"ring_data.pkl\")\n",
    "\n",
    "\n",
    "print(\"Data saved to CSV file in locs folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: rec.array([(   55, 286.94257, 446.89218, 3502.5276, 1.8671156, 0.9978297 , 80.892395, 0.06263571, 0.02721411, 0.46557692, 11063.124 , 186.02939, 0.01958825,  59.230602 , 151.27956, 0),\n",
      "           (   56, 286.4608 , 446.71573, 7612.213 , 1.7522103, 0.96453935, 88.88461 , 0.03346481, 0.01662372, 0.44952992, 23734.055 , 141.31807, 0.03546379,   5.4026055, 190.66795, 0),\n",
      "           (   57, 286.48608, 446.76953, 8011.8667, 1.8225521, 0.9628848 , 85.75826 , 0.03383575, 0.01607805, 0.47168326, 24546.97  , 167.2068 , 0.03656639,  13.04658  , 191.8112 , 0),\n",
      "           ...,\n",
      "           (14809, 287.55243, 448.2808 , 5361.7026, 2.2095728, 1.1128038 , 61.288536, 0.05447531, 0.02306123, 0.4963715 , 14426.991 , 257.57446, 0.02185672, 253.4097   , 185.4469 , 0),\n",
      "           (14810, 287.46918, 448.23654, 5594.4595, 2.0749352, 1.0684788 , 60.240303, 0.04823198, 0.02149085, 0.48505437, 15630.1875, 239.2464 , 0.00802789, 242.6199   , 191.26102, 0),\n",
      "           (14811, 287.41733, 448.29565, 5277.426 , 2.089033 , 1.0613587 , 67.648125, 0.05201538, 0.0222911 , 0.4919378 , 15054.205 , 230.57492, 0.00394906, 245.275    , 201.13206, 0)],\n",
      "          dtype=[('frame', '<u4'), ('x', '<f4'), ('y', '<f4'), ('photons', '<f4'), ('sx', '<f4'), ('sy', '<f4'), ('bg', '<f4'), ('lpx', '<f4'), ('lpy', '<f4'), ('ellipticity', '<f4'), ('net_gradient', '<f4'), ('z', '<f4'), ('d_zcalib', '<f4'), ('x_pick_rot', '<f4'), ('y_pick_rot', '<f4'), ('group', '<i4')])}\n",
      "<class 'dict'>\n",
      "<class 'numpy.recarray'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
