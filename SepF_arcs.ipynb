{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aecf24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "from matplotlib import pyplot as plt, cm, colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import shutil\n",
    "\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.despine()\n",
    "from matplotlib import pyplot as plt, cm, colors\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import glob\n",
    "import os.path as ospath\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from sys import executable\n",
    "from subprocess import check_output\n",
    "from PyQt5.QtWidgets import QFileDialog, QApplication\n",
    "from IPython.display import HTML\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.spatial import distance\n",
    "from scipy import linalg\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "from picasso.picasso import io\n",
    "from picasso.picasso.postprocess import link, compute_dark_times\n",
    "from picasso.picasso.render import render\n",
    "from picasso.picasso.gui.render import estimate_kinetic_rate, fit_cum_exp\n",
    "from picasso.picasso.lib import append_to_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d86f2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(dirname):\n",
    "    \n",
    "    os.chdir(dirname)\n",
    "    files = glob.glob(\"*.hdf5\")\n",
    "    \n",
    "    if files:\n",
    "        print(\"{} HDF5 files found.\".format(len(files)))\n",
    "    else:\n",
    "        print(\"No HDF5 files found at: {}\".format(dirname))\n",
    "            \n",
    "    return files\n",
    "\n",
    "def load_arc_data_df(dirname, filename):\n",
    "    file = ospath.join(dirname, filename)\n",
    "\n",
    "    try: \n",
    "        df = pd.read_pickle(file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"No results of previously analyzed datasets were detected.\")\n",
    "        return None\n",
    "    else: \n",
    "        print(\"Results of previously analyzed datasets were detected.\")\n",
    "        return df\n",
    "    \n",
    "def identify_new_files(files, df_ring_data):\n",
    "    \"\"\"\n",
    "    Identify which files have already been analyzed previously. \n",
    "    Return list of new files for processing\n",
    "    \"\"\"\n",
    "    new_files = []\n",
    "    for file in files:\n",
    "        if file not in df_ring_data['filename'].values:\n",
    "            new_files.append(file)\n",
    "    \n",
    "    n_old = len(files)-len(new_files)\n",
    "    n_new = len(new_files)\n",
    "    if n_old == 1:\n",
    "        print(\" {} HDF5 file was previously analyzed.\".format(n_old))\n",
    "    else: \n",
    "        print(\" {} HDF5 files were previously analyzed.\".format(n_old))\n",
    "        \n",
    "    if n_new == 1:\n",
    "        print(\" {} HDF5 file is new and will be analyzed.\".format(n_new))\n",
    "    else: \n",
    "        print(\" {} HDF5 files are new and will be analyzed.\".format(n_new))\n",
    "        \n",
    "    return new_files\n",
    "\n",
    "def identify_fov_cell_type(df_ring_data, filenames, fov_id_start):\n",
    "    \"\"\"\n",
    "    For each file identify \n",
    "    - cell type: sporulating or vegetative cells\n",
    "    - fov index: fov from which the picks were generated\n",
    "    Results will be saved in a dataframe with columns:\n",
    "    'fov_id', 'filename', 'cell_type'\n",
    "    \n",
    "    If some files have been analyzed before the current script execution \n",
    "    the results were saved in the ring_data file and loaded to df_ring_data.\n",
    "    (columns: \"fov_id\", \"cell_type\", \"filename\", \"group\", ... where \n",
    "    group are the pick ids.)\n",
    "    If no prior analysis results exist, then df_ring_data = None. \n",
    "    Therefore we can check if a new file belongs to a previously analyzed fov.\n",
    "    \n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "    filenames_no_cell_type = []\n",
    "    \n",
    "    fov_id_counter = fov_id_start + 1\n",
    "    \n",
    "    for i, filename in enumerate(filenames):\n",
    "        # cell type: spor or veg:\n",
    "        cell_type = np.nan\n",
    "                \n",
    "        spor_found = re.search('spor', filename, re.IGNORECASE)\n",
    "        veg_found = re.search('veg', filename, re.IGNORECASE)\n",
    "        \n",
    "        if spor_found and not veg_found:\n",
    "            cell_type = 'spor'\n",
    "        elif not spor_found and veg_found:\n",
    "            cell_type = 'veg'\n",
    "        elif spor_found and veg_found:\n",
    "            # consider the string occuring first as cell type determining string\n",
    "            spor_found_location = spor_found.start()\n",
    "            veg_found_location = veg_found.start()\n",
    "            \n",
    "            if spor_found_location < veg_found_location:\n",
    "                cell_type = 'spor'\n",
    "            else:\n",
    "                cell_type = 'veg'\n",
    "        else:\n",
    "            cell_type = np.nan\n",
    "            filenames_no_cell_type.append(filename)\n",
    "            \n",
    "\n",
    "        \n",
    "        # search if a file from the same fov was already registered:\n",
    "        if not pd.isnull(cell_type):\n",
    "            # get substrings of filename that do not contain the cell_type string.\n",
    "            filename_substrings = re.split(cell_type, filename, flags = re.IGNORECASE)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # check if an already registered file exists that contains the substrings\n",
    "            filenames_found = []\n",
    "            old_or_new_file = [] # True if file from previous run of the script, False if new file.\n",
    "            for filename2 in dictionary.keys(): # search in files that were already registered.\n",
    "                contained = all([substring in filename2 for substring in filename_substrings])\n",
    "                if contained and filename != filename2:\n",
    "                    filenames_found.append(filename2)\n",
    "                    old_or_new_file.append(False)\n",
    "            if isinstance(df_ring_data, pd.DataFrame):\n",
    "                previously_analyzed_files = np.unique(df_ring_data['filename'])\n",
    "                for filename2 in previously_analyzed_files:\n",
    "                    contained = all([substring in filename2 for substring in filename_substrings])\n",
    "                    if contained and filename != filename2:\n",
    "                        filenames_found.append(filename2)\n",
    "                        old_or_new_file.append(True)\n",
    "            \n",
    "            # if one other file was found: assign the existing fov index to the newly registred file\n",
    "            # if no other file was found: assign a new fov index to the newly registered file\n",
    "            if len(filenames_found) > 1:\n",
    "                raise Exception('''Files from the same FOV than ''' + filename + ''' where searched. \n",
    "                However more than one other file was detected: \n",
    "                ''' + '\\n'.join(filenames_found))\n",
    "            elif len(filenames_found) == 1:\n",
    "                filename_found = filenames_found[0]\n",
    "                if old_or_new_file[0]: # filename_found is from previous run of the script\n",
    "                    fov_id = df_ring_data.loc[df_ring_data['filename'] == filename_found, 'fov_id'].iloc[0]\n",
    "                if not old_or_new_file[0]: # filename_found is also a new file.\n",
    "                    fov_id = dictionary[filename_found][0]\n",
    "            else: # No file from the same fov previously registered\n",
    "                fov_id = fov_id_counter\n",
    "                fov_id_counter += 1\n",
    "        \n",
    "        else:\n",
    "            fov_id = np.nan\n",
    "            \n",
    "        dictionary[filename] = [fov_id, filename, cell_type]\n",
    "        \n",
    "    df_results = pd.DataFrame.from_dict(dictionary, orient = 'index', columns = ['fov_id', 'filename', 'cell_type'])\n",
    "    df_results = df_results.reset_index()\n",
    "\n",
    "    print()\n",
    "    print('The cell type (spr or veg) of these files could not be determined')\n",
    "    print('and thus cannot be used for further analysis:')\n",
    "    for filename in filenames_no_cell_type:\n",
    "        print(' -', filename)\n",
    "        \n",
    "    return df_results\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "\n",
    "    try:\n",
    "        locs, info = io.load_locs(path)\n",
    "    except io.NoMetadataFileError:\n",
    "        return None, None, None\n",
    "    \n",
    "    try:\n",
    "        pixelsize = info[1][\"Pixelsize\"]\n",
    "    except:  \n",
    "        print(\"No pixelsize found in yaml file. Default 130 nm used.\")\n",
    "  \n",
    "    if hasattr(locs, \"x_pick_rot\"):\n",
    "\n",
    "        # convert px to nm\n",
    "        locs.x *= pixelsize\n",
    "        locs.y *= pixelsize\n",
    "        locs.x_pick_rot *= pixelsize\n",
    "        locs.y_pick_rot *= pixelsize\n",
    "        \n",
    "        return locs, info, pixelsize\n",
    "    else:\n",
    "        print('x_pick_rot column is missing!')\n",
    "        return None, None, None\n",
    "\n",
    "def double_gaus(x,a,x0,sigma, b, x1, sigma1):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2)) + b*np.exp(-(x-x1)**2/(2*sigma1**2))\n",
    "\n",
    "def gaus(x,a,x0,sigma):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2)) \n",
    "\n",
    "def histogram(data, binning=100, column = \"y\"):\n",
    "    # histogram\n",
    "    n, bins = np.histogram(data[column], bins=binning)\n",
    "    centers = (bins[:-1] + bins[1:]) / 2\n",
    "    hist_data = [n, centers]\n",
    "    return hist_data\n",
    "\n",
    "def fit_peaks(data, p0, binning=100, column = \"y\", hist_data = None):\n",
    "    if hist_data is None:\n",
    "        hist_data = histogram(data, binning, column)\n",
    "    \n",
    "    n = hist_data[0]\n",
    "    centers = hist_data[1]\n",
    "    \n",
    "    try:\n",
    "        p_fit, p_cov = optimize.curve_fit(double_gaus, centers, n, p0=p0)\n",
    "    except:\n",
    "        p_fit = [0,0,0,0,0,0]\n",
    "        \n",
    "    p_fit[2] = np.abs(p_fit[2])\n",
    "    p_fit[5] = np.abs(p_fit[5])\n",
    "    \n",
    "    return p_fit, hist_data\n",
    "\n",
    "def fit_peak(data, p0, binning=100, column = \"y\", hist_data = None):\n",
    "    if hist_data is None:\n",
    "        hist_data = histogram(data, binning, column)\n",
    "    \n",
    "    n = hist_data[0]\n",
    "    centers = hist_data[1]\n",
    "    \n",
    "    try:\n",
    "        p_fit, p_cov = optimize.curve_fit(gaus, centers, n, p0=p0)\n",
    "    except:\n",
    "        p_fit = np.array([0,0,0])\n",
    "        \n",
    "    p_fit[2] = np.abs(p_fit[2])\n",
    "    \n",
    "    return p_fit, hist_data\n",
    "\n",
    "def find_peaks(data, binning=100, axes=\"y\"):\n",
    "    \n",
    "    if axes == \"y\":\n",
    "        column = \"y_pick_rot\"\n",
    "    elif axes == \"x\":\n",
    "        column = \"x_pick_rot\"\n",
    "    elif axes == \"xyz\":\n",
    "        column = 2\n",
    "    elif axes == \"z\":\n",
    "        column = \"z\"\n",
    "    \n",
    "    # find peaks\n",
    "    \n",
    "    bandwidth = estimate_bandwidth(data[column].reshape(-1, 1), quantile=0.2, n_samples=binning)\n",
    "    #print(\"estimated bandwidth: \"+str(bandwidth))\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(data[column].reshape(-1, 1))\n",
    "    labels = ms.labels_\n",
    "    peaks = np.sort(ms.cluster_centers_[0:2],axis=None) # assuming that there are two large peaks from the two rings\n",
    "    peak1 = float(peaks[0])\n",
    "    peak2 = float(peaks[1])\n",
    "    # use fixed starting values if the peak1 and peak2 values are absurd\n",
    "    if peak1 < data[column].min():\n",
    "        peak1 = -30\n",
    "    if peak2 > data[column].max():\n",
    "        peak1 = 30\n",
    "    estimated_peaks = {0:peak1, 1:peak2}\n",
    "    \n",
    "    \"\"\"\n",
    "    hist_data = histogram(data, binning, column)\n",
    "    n = hist_data[0]\n",
    "    centers = hist_data[1]\n",
    "    n_left = n[centers<0]\n",
    "    n_right = n[centers>=0]\n",
    "    n_left_max = n_left.max()\n",
    "    n_right_max = n_right.max()\n",
    "    peak1 = float(centers[n == n_left_max])\n",
    "    peak2 = float(centers[n == n_right_max])\n",
    "    estimated_peaks = {0:peak1, 1:peak2}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # fit peaks\n",
    "    p0 = [peak1/2, peak1, 10, peak1/2, peak2, 10]\n",
    "    #p_fit, hist_data = fit_peaks(data, p0, binning=binning, column = column, hist_data = hist_data)\n",
    "    p_fit, hist_data = fit_peaks(data, p0, binning=binning, column = column)\n",
    "    \n",
    "    \n",
    "    # check order of fitted peaks (peak 1 < peak 2)\n",
    "    if p_fit[1] > p_fit[4]:\n",
    "        p_temp = p_fit.copy()\n",
    "        p_fit[0:3]=p_temp[3:6]\n",
    "        p_fit[3:6]=p_temp[0:3]\n",
    "       \n",
    "        \n",
    "    # p_fit: amplitued_1, center_1, width_1, amplitude_2, center_2, width_2\n",
    "        \n",
    "    return estimated_peaks, p_fit, hist_data\n",
    "\n",
    "def find_peak(data, binning=100, axes=\"y\"):\n",
    "    \n",
    "    if axes == \"y\":\n",
    "        column = \"y_pick_rot\"\n",
    "    elif axes == \"x\":\n",
    "        column = \"x_pick_rot\"\n",
    "    elif axes == \"xyz\":\n",
    "        column = 2\n",
    "    elif axes == \"z\":\n",
    "        column = \"z\"\n",
    "    \n",
    "    # find peak\n",
    "    bandwidth = estimate_bandwidth(data[column].reshape(-1, 1), quantile=0.2, n_samples=binning)\n",
    "    #print(\"estimated bandwidth: \"+str(bandwidth))\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    ms.fit(data[column].reshape(-1, 1))\n",
    "    labels = ms.labels_\n",
    "   # print(ms.cluster_centers_[0:2])\n",
    "    peaks = np.sort(ms.cluster_centers_[0:2], axis=None)\n",
    "    peak1 = float(ms.cluster_centers_[0])\n",
    "    estimated_peaks = {0:peak1}\n",
    "    \n",
    "    # fit peaks\n",
    "    p0 = [peak1/2, peak1, 40]\n",
    "    \n",
    "    p_fit, hist_data = fit_peak(data, p0, binning, column = column)\n",
    "    #print(estimated_peaks)\n",
    "    return estimated_peaks, p_fit, hist_data\n",
    "\n",
    "def plot_peak_dist(data, hist_data, p_fit, axes=\"y\", ax=None):\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    if axes == \"y\":\n",
    "        column = \"y_pick_rot\"\n",
    "        xlabel = \"y (nm)\"\n",
    "    elif axes == \"x\":\n",
    "        column = \"x_pick_rot\"\n",
    "        xlabel = \"x (nm)\"\n",
    "    elif axes == \"z\":\n",
    "        column = \"z\"\n",
    "        xlabel = \"z (nm)\"\n",
    "    elif axes == \"xyz\":\n",
    "        column == 1\n",
    "    \n",
    "    n = hist_data[0]\n",
    "    bins = hist_data[1]\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(9, 5))\n",
    "    binwidth = bins[1]-bins[0]\n",
    "    ax.bar(bins, n, width=binwidth, color=gray)\n",
    "    xlin = np.linspace(data[column].min(), data[column].max(), 1000)\n",
    "    ax.plot(xlin, gaus(xlin,*p_fit[0:3]), c=red, linewidth=2)\n",
    "    ax.plot(xlin, gaus(xlin,*p_fit[3:6]), c=red, linewidth=2)\n",
    "    ax.set_title(\"Line profile\",loc=\"left\",fontsize=14)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"Counts\")  \n",
    "    \n",
    "    ax.text(0.5,\n",
    "            0.9,\n",
    "            (\"Fitted Peaks:\\n\"\n",
    "            \"Peak 1 at {:.1f} nm, $\\sigma$ = {:.1f} nm\\n\"\n",
    "            \"Peak 2 at {:.1f} nm, $\\sigma$ = {:.1f} nm\\n\"\n",
    "            \"Distance: {:.1f} nm\").format(p_fit[1],p_fit[2],p_fit[4],p_fit[5], p_fit[4]-p_fit[1]),\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"center\",\n",
    "            transform = ax.transAxes,\n",
    "            fontsize=12)\n",
    "    \"\"\"\n",
    "    ax.text(0.15,\n",
    "            0.7,\n",
    "            (\"Estimated Peaks:\\n\"\n",
    "            \"Peak 1 at {:.1f} nm\\n\"\n",
    "            \"Peak 2 at {:.1f} nm\\n\"\n",
    "            \"Fitted Peaks:\\n\"\n",
    "            \"Peak 1 at {:.1f} nm\\n\"\n",
    "            \"Peak 2 at {:.1f} nm\").format(peak1,peak2,p_fit[1],p_fit[4]),\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"center\",\n",
    "            transform = ax.transAxes,\n",
    "            fontsize=12)\n",
    "    \"\"\"\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_peak(data, hist_data, p_fit, axes=\"y\", ax=None):\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    if axes == \"y\":\n",
    "        column = \"y_pick_rot\"\n",
    "        xlabel = \"y (nm)\"\n",
    "    elif axes == \"x\":\n",
    "        column = \"x_pick_rot\"\n",
    "        xlabel = \"x (nm)\"\n",
    "    elif axes == \"z\":\n",
    "        column = \"z\"\n",
    "        xlabel = \"z (nm)\"\n",
    "    elif axes == \"xyz\":\n",
    "        column == 1\n",
    "    \n",
    "    n = hist_data[0]\n",
    "    bins = hist_data[1]\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize=(9, 5))\n",
    "    binwidth = bins[1]-bins[0]\n",
    "    ax.bar(bins, n, width=binwidth, color=gray)\n",
    "    xlin = np.linspace(data[column].min(), data[column].max(), 1000)\n",
    "    ax.plot(xlin, gaus(xlin,*p_fit[0:3]), c=red, linewidth=2)\n",
    "    ax.set_title(\"Line profile ({})\".format(axes),loc=\"left\",fontsize=14)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(\"Counts\")  \n",
    "    \n",
    "    ax.text(0.5,\n",
    "            0.9,\n",
    "            (\"Fitted Peak:\\n\"\n",
    "            \"Peak at {:.1f} nm, $\\sigma$ = {:.1f} nm\").format(p_fit[1],p_fit[2]),\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"center\",\n",
    "            transform = ax.transAxes,\n",
    "            fontsize=12)\n",
    "\n",
    "\n",
    "    return ax\n",
    "\n",
    "def plot_locs_z_colormap(data, axes, title, fig, ax):\n",
    "\n",
    "    # Generate data...\n",
    "    if axes == \"y_pick_rot\":\n",
    "        x = data.y_pick_rot\n",
    "        y = data.x_pick_rot\n",
    "        z = data.z\n",
    "        ax.set_ylabel(\"x (nm)\")\n",
    "        ax.set_xlabel(\"y (nm)\") \n",
    "    elif axes == \"y\":\n",
    "        x = data.y\n",
    "        y = data.x\n",
    "        z = data.z\n",
    "        ax.set_ylabel(\"x (nm)\")\n",
    "        ax.set_xlabel(\"y (nm)\") \n",
    "    elif axes == \"x_pick_rot\":\n",
    "        x = data.x_pick_rot\n",
    "        y = data.y_pick_rot\n",
    "        z = data.z\n",
    "        ax.set_xlabel(\"x (nm)\")\n",
    "        ax.set_ylabel(\"y (nm)\")\n",
    "    elif axes == \"x\":\n",
    "        x = data.x\n",
    "        y = data.y\n",
    "        z = data.z\n",
    "        ax.set_xlabel(\"x (nm)\")\n",
    "        ax.set_ylabel(\"y (nm)\")  \n",
    "    elif axes == \"z\":\n",
    "        x = data.x_pick_rot\n",
    "        y = data.z\n",
    "        z = data.z\n",
    "        ax.set_xlabel(\"x (nm)\")\n",
    "        ax.set_ylabel(\"z (nm)\")  \n",
    "    \n",
    "    sc = ax.scatter(x, y, s = 30, c=z, cmap='jet')\n",
    "    fig.colorbar(sc, ax = ax)\n",
    "    \n",
    "    #ax.set_aspect('equal', adjustable='datalim')\n",
    "\n",
    "    ax.set_title(title,loc=\"left\",fontsize=14)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def render_locs(x1, x2, locs, path, folder, pixelsize, oversampling, blur_method = 'smooth', vmin = None, vmax = None, cmap = 'hot', viewport = None, save = True):\n",
    "\n",
    "    export_locs = locs.copy()\n",
    "    \n",
    "    export_locs.x \n",
    "    export_locs.y \n",
    "    \n",
    "    plot_locs = export_locs.copy()\n",
    "    if x1 == 'x':\n",
    "        plot_locs.x = export_locs.x\n",
    "    if x2 == 'x':\n",
    "        plot_locs.y = export_locs.x\n",
    "    if x1 == 'y':\n",
    "        plot_locs.x = export_locs.y\n",
    "    if x2 == 'y':\n",
    "        plot_locs.y = export_locs.y\n",
    "    if x1 == 'z':\n",
    "        plot_locs.x = export_locs.z\n",
    "    if x2 == 'z':\n",
    "        plot_locs.y = export_locs.z\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    if viewport is None:\n",
    "        x_min = np.min(plot_locs.x)    \n",
    "        x_max = np.max(plot_locs.x)\n",
    "        y_min = np.min(plot_locs.y)\n",
    "        y_max = np.max(plot_locs.y)\n",
    "    \n",
    "        frame_x = (x_max-x_min)/10\n",
    "        frame_y = (y_max-y_min)/5\n",
    "    \n",
    "        viewport =  (y_min-frame_y, x_min-frame_x), (y_max+frame_y, x_max+frame_x)\n",
    "    else:\n",
    "        viewport = viewport\n",
    "    \n",
    "    len_x, image = render(plot_locs, viewport = viewport, oversampling=oversampling, blur_method=blur_method)\n",
    "    \n",
    "    img_name = \"{}.png\".format('image')\n",
    "    img_path = os.path.join(path,folder)\n",
    "    img_path_name = os.path.join(img_path,img_name)\n",
    "    \n",
    "    if not os.path.isdir(img_path):\n",
    "        os.makedirs(img_path)\n",
    "\n",
    "\n",
    "    if len(image) % 2 != 0:\n",
    "\n",
    "        image = np.append(image,[image[-1]], axis=0)\n",
    "\n",
    "    if len(image[0]) % 2 != 0:\n",
    "\n",
    "        image = np.append(image,np.expand_dims(image[:,-1], axis=1), axis=1)\n",
    "\n",
    "    if save:\n",
    "        plt.imsave(img_path_name, image, vmin = vmin, vmax = vmax, cmap = cmap)\n",
    "\n",
    "\n",
    "\n",
    "    return image\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f6a005",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f9cee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 HDF5 files found.\n"
     ]
    }
   ],
   "source": [
    "#path = gui_fname()\n",
    "path = r'X:\\users\\kcramer\\sporPAINT\\SepF\\Picked_Arcs_SepF'\n",
    "#path = r'W:\\users\\reinhardt\\z.software\\Git\\spor-PAINT\\dev_sr\\spor-paint\\SepF\\subset'\n",
    "filenames_all = load_files(path)\n",
    "\n",
    "# filter fits that did not work properly\n",
    "#  1. fit did not converge (all parameters == 0)\n",
    "#  2. distance between peaks > pick width\n",
    "#  3. amplitude of at least one of the peaks is <= 0\n",
    "#  4. sigma of at least one of the peaks is > 30 nm or < 2nm\n",
    "sigma_max = 20 # nm\n",
    "sigma_min = 1 # nm\n",
    "\n",
    "plotting = True\n",
    "binning = 30 # binning for peak histogram\n",
    "binning_z = 30\n",
    "\n",
    "slice_thickness = 100 # nm\n",
    "variable_slice_thickness = True # change to \"False\" if you want a fixed slice thickness. Otherwise the parameterslice_thickness won't be used. \n",
    "if variable_slice_thickness:\n",
    "    slice_cutoff = 1.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3702655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results of previously analyzed datasets were detected.\n",
      "\n",
      "The cell type (spr or veg) of these files could not be determined\n",
      "and thus cannot be used for further analysis:\n"
     ]
    }
   ],
   "source": [
    "# Check if some of the found hdf5 files were already analyzed?\n",
    "# If yes, open ring_data dataframe with previous results.\n",
    "df_arc_data = load_arc_data_df(path, \"arc_data.pkl\")\n",
    "\n",
    "\n",
    "# Identify which files have not yet been analyzed.\n",
    "if df_arc_data is not None:\n",
    "    filenames = identify_new_files(filenames_all, df_arc_data)\n",
    "    fov_id_start = df_arc_data['fov_id'].max()\n",
    "else:\n",
    "    filenames = filenames_all\n",
    "    fov_id_start = 0\n",
    "\n",
    "# Create a dictionary that saves which file was taken from which FOV and which cell types are contained (spor or veg)\n",
    "# {filename_1: (FOV_id, 'spor'), filename_2: (FOV_id, 'veg'), ...}\n",
    "df_fov_file_assign = identify_fov_cell_type(df_arc_data, filenames, fov_id_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "058c8f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOV ID: 1\n",
      "  spor : Spor_SepF_arcs_230317_fov1_2plex_kcb1113_375pM-r3_DP_SepF_1_drift_aligned_picked.hdf5\n",
      "  veg  : Veg_SepF_arcs_230317_fov1_2plex_kcb1113_375pM-r3_DP_SepF_1_drift_aligned_picked.hdf5\n"
     ]
    }
   ],
   "source": [
    "for fov_id in range(int(fov_id_start)+1, int(df_fov_file_assign['fov_id'].max())+1):\n",
    "    \n",
    "    print('FOV ID:', fov_id)\n",
    "    files_fov_id = df_fov_file_assign.loc[df_fov_file_assign['fov_id'] == fov_id]\n",
    "\n",
    "    \n",
    "    print('  spor : ', end = '')\n",
    "\n",
    "    spor_name = files_fov_id.loc[files_fov_id['cell_type'] == 'spor']['filename']\n",
    "    if spor_name.empty:\n",
    "        print('--')\n",
    "    else:\n",
    "        print(spor_name.iloc[0])\n",
    "\n",
    "        \n",
    "    print('  veg  : ', end = '')\n",
    "\n",
    "    veg_name = files_fov_id.loc[files_fov_id['cell_type'] == 'veg']['filename']\n",
    "    if veg_name.empty:\n",
    "        print('--')\n",
    "    else:\n",
    "        print(veg_name.iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215e983",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7ca768d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4d8bfef3b8436799c70abb3216227d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Veg_SepF_arcs_230317_fov1_2plex_kcb1113_375pM-r3_DP_SepF_1_drift_aligned_picked.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2c4e84a5a84098857e6cc57b8592a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing picks:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((-0.032357352513533374, -0.3763934819148137), (0.27302501385028544, 0.5910691504845252))\n",
      "X:\\users\\kcramer\\sporPAINT\\SepF\\Picked_Arcs_SepF\\analysis\\fov_1_veg_pick_0_zfilter\n",
      "[  19.89521578 -255.49019415   34.70352886]\n",
      "<class 'numpy.ndarray'>\n",
      "X:\\users\\kcramer\\sporPAINT\\SepF\\Picked_Arcs_SepF\\analysis\\fov_1_veg_pick_0_zfilter_arc\n",
      "((-0.030577330405895525, -0.4494666971059946), (0.21162498180682843, 0.5651729501577524))\n",
      "X:\\users\\kcramer\\sporPAINT\\SepF\\Picked_Arcs_SepF\\analysis\\fov_1_veg_pick_1_zfilter\n",
      "[   7.31856034 -101.74351802   22.89404622]\n",
      "<class 'numpy.ndarray'>\n",
      "X:\\users\\kcramer\\sporPAINT\\SepF\\Picked_Arcs_SepF\\analysis\\fov_1_veg_pick_1_zfilter_arc\n",
      "\n",
      "Spor_SepF_arcs_230317_fov1_2plex_kcb1113_375pM-r3_DP_SepF_1_drift_aligned_picked.hdf5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872322c252b745079feb65e220f3950b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing picks:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((-0.044406259564252995, -0.6325429135836088), (0.2748344685481145, 0.6129100752610427))\n",
      "X:\\users\\kcramer\\sporPAINT\\SepF\\Picked_Arcs_SepF\\analysis\\fov_1_spor_pick_0_zfilter\n",
      "[125.97077715   8.46176382  17.04429068]\n",
      "<class 'numpy.ndarray'>\n",
      "X:\\users\\kcramer\\sporPAINT\\SepF\\Picked_Arcs_SepF\\analysis\\fov_1_spor_pick_0_zfilter_arc\n",
      "((-0.059547970203252934, -0.5666847839355469), (0.36167773907001205, 0.5334693638728216))\n",
      "X:\\users\\kcramer\\sporPAINT\\SepF\\Picked_Arcs_SepF\\analysis\\fov_1_spor_pick_1_zfilter\n",
      "[ 135.89824967 -102.15611359   27.01808291]\n",
      "<class 'numpy.ndarray'>\n",
      "X:\\users\\kcramer\\sporPAINT\\SepF\\Picked_Arcs_SepF\\analysis\\fov_1_spor_pick_1_zfilter_arc\n",
      "\n",
      "The following files could not be loaded.\n",
      "Probably they miss the x_pick_rot column:\n",
      "Data saved to CSV file in locs folder.\n"
     ]
    }
   ],
   "source": [
    "# image export settings\n",
    "img_format = \".png\"\n",
    "dpi = 100\n",
    "\n",
    "# define colors:\n",
    "blue = \"#4C72B0\"\n",
    "orange = \"#DD8452\"\n",
    "red = \"#C44E52\"\n",
    "gray = \"#90A8CE\"\n",
    "\n",
    "#prepare analysis folder\n",
    "analysis_folder = os.path.join(path, \"analysis\")\n",
    "if not os.path.isdir(analysis_folder):\n",
    "    os.makedirs(analysis_folder)\n",
    "excluded_folder = os.path.join(path, 'analysis', 'excluded_filter')\n",
    "if not os.path.isdir(excluded_folder):\n",
    "    os.makedirs(excluded_folder)\n",
    "    \n",
    "# reset old _arc.png files\n",
    "# move fov_1_spor_arc.png back to analysis folder\n",
    "for image_path in glob.glob(os.path.join(excluded_folder, '*_arc.png')):\n",
    "    os.remove(image_path)\n",
    "\n",
    "# remove _arc.png files from analysis folder\n",
    "for image_path in glob.glob(os.path.join(analysis_folder, '*_arc.png')):\n",
    "    os.remove(image_path)\n",
    "    \n",
    "    \n",
    "# reset old _arg.png files\n",
    "# move fov_1_spor_arc.png back to analysis folder\n",
    "for image_path in glob.glob(os.path.join(excluded_folder, '*_zfilter.png')):\n",
    "    os.remove(image_path)\n",
    "    \n",
    "# remove _arc.png files from analysis folder\n",
    "for image_path in glob.glob(os.path.join(analysis_folder, '*_zfilter.png')):\n",
    "    os.remove(image_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "files_no_x_pick_rot = []\n",
    "arc_data = []\n",
    "#iterate over locs in directory:\n",
    "for filename in tqdm(filenames, desc=\"Processing files\"):\n",
    "    print()\n",
    "    print(filename)\n",
    "    \n",
    "    fov_id = df_fov_file_assign.loc[df_fov_file_assign['filename'] == filename]['fov_id'].iloc[0]\n",
    "    cell_type = df_fov_file_assign.loc[df_fov_file_assign['filename'] == filename]['cell_type'].iloc[0]\n",
    "\n",
    "    \n",
    "    if np.isnan(fov_id):\n",
    "        print('FOV ID is nan.')\n",
    "        continue\n",
    "    fov_id = int(fov_id)\n",
    "    \n",
    "    #load locs and convert distances from px to nm (Attention!)\n",
    "    locs, info, pixelsize = load_data(os.path.join(path,filename))\n",
    "    \n",
    "    if locs is None:\n",
    "        files_no_x_pick_rot.append(filename)\n",
    "        print(\"File {} not loaded.\".format(filename))\n",
    "        continue\n",
    "    \n",
    "    # iterate over picks in a file \n",
    "    for pick in tqdm(np.unique(locs.group), desc=\"Processing picks\"):\n",
    "     \n",
    "        # select locs from pick\n",
    "        pick_locs = locs[locs.group == pick]\n",
    "        \n",
    "        \n",
    "        ################\n",
    "        # (0) filter in z: take a slice of +- slice_thickness/2\n",
    "        ################\n",
    "        \n",
    "        estimated_peaks, r_par, hist_data = find_peak(pick_locs, binning=binning_z, axes=\"z\")\n",
    "        \n",
    "        if variable_slice_thickness:\n",
    "            slice_thickness = slice_cutoff * r_par[2] * 2\n",
    "        \n",
    "        # set up plot with gridspec\n",
    "        fig0 = plt.figure(figsize=(18, 14), constrained_layout=True)\n",
    "        gs0 = fig0.add_gridspec(2,3)\n",
    "        fig0.suptitle((\"FOV {}, {}, Pick {} - z-filter for arc analysis \\n\"\n",
    "                          \"File: {}\").format(fov_id, cell_type, pick, filename), \n",
    "                      fontsize=16,\n",
    "                      ha=\"center\")\n",
    "\n",
    "        \n",
    "        # plot scatter plot for locs in pick with z colorcode\n",
    "        \n",
    "        \n",
    "        ax1 = fig0.add_subplot(gs0[0, 2])\n",
    "        ax1 = plot_locs_z_colormap(pick_locs, \n",
    "                             'z', \n",
    "                             title = 'Pick localizations',\n",
    "                             fig = fig0,\n",
    "                             ax = ax1)\n",
    "        \n",
    "        ax1.axhline(r_par[1]-(slice_thickness/2),c=blue, linewidth=2, linestyle=\"--\")\n",
    "        ax1.axhline(r_par[1]+(slice_thickness/2),c=blue, linewidth=2, linestyle=\"--\")\n",
    "        \n",
    "        ax2 = fig0.add_subplot(gs0[1, 2])\n",
    "        ax2 = plot_peak(pick_locs,\n",
    "                       hist_data,\n",
    "                       r_par,\n",
    "                       axes=\"z\",\n",
    "                       ax=ax2)\n",
    "        \n",
    "        ax2.axvline(r_par[1]-(slice_thickness/2),c=blue, linewidth=2, linestyle=\"--\")\n",
    "        ax2.axvline(r_par[1]+(slice_thickness/2),c=blue, linewidth=2, linestyle=\"--\")\n",
    "\n",
    "        \n",
    "        #ax1.set_xlim(ax2.get_xlim())\n",
    "        #ax1.set_xlim(xmin = 0, xmax = 20)\n",
    "        \n",
    "        x_min, x_max = ax1.get_xlim()\n",
    "        z_min, z_max = ax1.get_ylim()\n",
    "        \n",
    "        viewport_xz = (z_min/pixelsize, x_min/pixelsize), (z_max/pixelsize, x_max/pixelsize)\n",
    "        \n",
    "        frame_x = (x_max-x_min)/10\n",
    "        frame_y = (pick_locs.y_pick_rot.max()-pick_locs.y_pick_rot.min())/5\n",
    "        viewport_xy = ((pick_locs.y_pick_rot.min()-frame_y)/pixelsize, (x_min-frame_x)/pixelsize), ((pick_locs.y_pick_rot.max()+frame_y)/pixelsize, (x_max+frame_x)/pixelsize)\n",
    "\n",
    "        print(viewport_xy)\n",
    "        #(y_min, x_min), (y_max, x_max) = viewport\n",
    "        \n",
    "        # xz\n",
    "        pick_locs_plot = pick_locs.copy()\n",
    "        pick_locs_plot['x'] = pick_locs_plot['x_pick_rot']/pixelsize\n",
    "        pick_locs_plot['y'] = pick_locs_plot['y_pick_rot']/pixelsize\n",
    "        pick_locs_plot['z'] = pick_locs_plot['z']/pixelsize\n",
    "        image = render_locs('x', 'z', pick_locs_plot,\n",
    "                        path, \n",
    "                        'analysis', \n",
    "                        pixelsize, \n",
    "                        oversampling = 400, \n",
    "                        blur_method = 'gaussian_iso', #'gaussian_iso'\n",
    "                        vmin = None,\n",
    "                        vmax = None,\n",
    "                        cmap = 'hot',\n",
    "                        viewport = viewport_xz, \n",
    "                        save = False)\n",
    "        \n",
    "        ax0 = fig0.add_subplot(gs0[0, 1])\n",
    "        ax0.imshow(image, aspect = 'equal', )\n",
    "        ax0.invert_yaxis()\n",
    "        ax0.grid(False)\n",
    "        ax0.get_yaxis().set_visible(False)\n",
    "        ax0.get_xaxis().set_visible(False)\n",
    "        \n",
    "        ax0.set_title(\"xz projection\",loc=\"left\",fontsize=14)\n",
    "        \n",
    "        # xy\n",
    "        image = render_locs('x', 'y', pick_locs_plot,\n",
    "                        path, \n",
    "                        'analysis', \n",
    "                        pixelsize, \n",
    "                        oversampling = 400, \n",
    "                        blur_method = 'gaussian_iso', #'gaussian_iso'\n",
    "                        vmin = None,\n",
    "                        vmax = None,\n",
    "                        cmap = 'hot',\n",
    "                        viewport = viewport_xy, \n",
    "                        save = False)\n",
    "        \n",
    "        ax3 = fig0.add_subplot(gs0[0, 0])\n",
    "        ax3.imshow(image, aspect = 'equal', )\n",
    "        ax3.invert_yaxis()\n",
    "        ax3.grid(False)\n",
    "        ax3.get_yaxis().set_visible(False)\n",
    "        ax3.get_xaxis().set_visible(False)\n",
    "        \n",
    "        ax3.set_title(\"xy projection\",loc=\"left\",fontsize=14)\n",
    "\n",
    "        \n",
    "        \n",
    "        # select locs within +- slice_thickness/2\n",
    "        \n",
    "        pick_locs = pick_locs[(pick_locs['z']>=r_par[1]-slice_thickness/2)&(pick_locs['z']<=r_par[1]+slice_thickness/2)]\n",
    "        \n",
    "        if len(pick_locs) != 0:\n",
    "            \n",
    "            # render locs inside of slice\n",
    "            pick_locs_plot = pick_locs.copy()\n",
    "            pick_locs_plot['x'] = pick_locs_plot['x_pick_rot']/pixelsize\n",
    "            pick_locs_plot['y'] = pick_locs_plot['y_pick_rot']/pixelsize\n",
    "            pick_locs_plot['z'] = pick_locs_plot['z']/pixelsize\n",
    "\n",
    "            # xz\n",
    "            image = render_locs('x', 'z', pick_locs_plot,\n",
    "                            path, \n",
    "                            'analysis', \n",
    "                            pixelsize, \n",
    "                            oversampling = 400, \n",
    "                            blur_method = 'gaussian_iso', #'gaussian_iso'\n",
    "                            vmin = None,\n",
    "                            vmax = None,\n",
    "                            cmap = 'hot',\n",
    "                            viewport = viewport_xz,\n",
    "                            save = False)\n",
    "\n",
    "            ax4 = fig0.add_subplot(gs0[1, 1])\n",
    "            ax4.imshow(image, aspect = 'equal', )\n",
    "            ax4.invert_yaxis()\n",
    "            ax4.grid(False)\n",
    "            ax4.get_yaxis().set_visible(False)\n",
    "            ax4.get_xaxis().set_visible(False)\n",
    "\n",
    "            ax4.set_title(\"xz projection ({:.1f} nm z-slice)\".format(slice_thickness),loc=\"left\",fontsize=14)\n",
    "\n",
    "\n",
    "            # xy\n",
    "            image = render_locs('x', 'y', pick_locs_plot,\n",
    "                            path, \n",
    "                            'analysis', \n",
    "                            pixelsize, \n",
    "                            oversampling = 400, \n",
    "                            blur_method = 'gaussian_iso', #'gaussian_iso'\n",
    "                            vmin = None,\n",
    "                            vmax = None,\n",
    "                            cmap = 'hot',\n",
    "                            viewport = viewport_xy, \n",
    "                            save = False)\n",
    "\n",
    "            ax5 = fig0.add_subplot(gs0[1, 0])\n",
    "            ax5.imshow(image, aspect = 'equal', )\n",
    "            ax5.invert_yaxis()\n",
    "            ax5.grid(False)\n",
    "            ax5.get_yaxis().set_visible(False)\n",
    "            ax5.get_xaxis().set_visible(False)\n",
    "        \n",
    "            ax5.set_title(\"xy projection ({:.1f} nm z-slice)\".format(slice_thickness),loc=\"left\",fontsize=14)\n",
    "\n",
    "        \n",
    "        img_zfilter_fname = \"fov_{}_{}_pick_{}_zfilter\".format(fov_id, cell_type, pick)\n",
    "        img_zfilter_name = os.path.join(analysis_folder, img_zfilter_fname)\n",
    "        fig0.savefig(img_zfilter_name+img_format, dpi=dpi, format=\"png\")\n",
    "        print(img_zfilter_name)\n",
    "\n",
    "        plt.close(fig0)\n",
    "        \n",
    "        \n",
    "        print(r_par)\n",
    "        print(type(r_par))\n",
    "        if (r_par == np.array([0,0,0])).all():\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        ################\n",
    "        # (1) estimate the postition of the two peaks using a histogram along the pick direction\n",
    "        ################\n",
    "        \n",
    "        estimated_peaks, r_par, hist_data = find_peaks(pick_locs, binning=binning, axes=\"x\")\n",
    "        distance = r_par[4]-r_par[1]\n",
    "        \n",
    "        # set up plot with gridspec\n",
    "        fig = plt.figure(figsize=(14, 16), constrained_layout=True)\n",
    "        gs = fig.add_gridspec(3, 1)\n",
    "        fig.suptitle((\"FOV {}, {}, Pick {} - Arc analysis\\n\"\n",
    "                          \"File: {}\").format(fov_id, cell_type, pick, filename), \n",
    "                      fontsize=16,\n",
    "                      ha=\"center\")\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        # plot scatter plot for locs in pick with z colorcode\n",
    "        \n",
    "        \n",
    "        ax1 = fig.add_subplot(gs[1, 0])\n",
    "        ax1 = plot_locs_z_colormap(pick_locs, \n",
    "                             'x_pick_rot', \n",
    "                             title = 'Pick localizations',\n",
    "                             fig = fig, \n",
    "                             ax = ax1)\n",
    "        \n",
    "        \n",
    "        ax2 = fig.add_subplot(gs[2, 0])\n",
    "        ax2 = plot_peak_dist(pick_locs,\n",
    "                       hist_data,\n",
    "                       r_par,\n",
    "                       axes=\"x\",\n",
    "                       ax=ax2)\n",
    "        \n",
    "        \n",
    "        ax1.set_xlim(ax2.get_xlim())\n",
    "        #ax1.set_xlim(xmin = 0, xmax = 20)\n",
    "        \n",
    "        x_min, x_max = ax1.get_xlim()\n",
    "        y_min, y_max = ax1.get_ylim()\n",
    "        \n",
    "        viewport = (y_min/pixelsize, x_min/pixelsize), (y_max/pixelsize, x_max/pixelsize)\n",
    "        #print(viewport)\n",
    "        #(y_min, x_min), (y_max, x_max) = viewport\n",
    "        \n",
    "        pick_locs_plot = pick_locs.copy()\n",
    "        pick_locs_plot['x'] = pick_locs_plot['x_pick_rot']/pixelsize\n",
    "        pick_locs_plot['y'] = pick_locs_plot['y_pick_rot']/pixelsize\n",
    "        image = render_locs('x', 'y', pick_locs_plot,\n",
    "                        path, \n",
    "                        'analysis', \n",
    "                        pixelsize, \n",
    "                        oversampling = 400, \n",
    "                        blur_method = 'gaussian_iso', #'gaussian_iso'\n",
    "                        vmin = None,\n",
    "                        vmax = None,\n",
    "                        cmap = 'hot', \n",
    "                        viewport = viewport, \n",
    "                        save = False)\n",
    "        \n",
    "        ax0 = fig.add_subplot(gs[0, 0])\n",
    "        ax0.imshow(image, aspect = 'equal', )\n",
    "        ax0.invert_yaxis()\n",
    "        ax0.grid(False)\n",
    "        ax0.get_yaxis().set_visible(False)\n",
    "        ax0.get_xaxis().set_visible(False)\n",
    "            \n",
    "        img_fname = \"fov_{}_{}_pick_{}_zfilter_arc\".format(fov_id, cell_type, pick)\n",
    "        img_name = os.path.join(analysis_folder, img_fname)\n",
    "        fig.savefig(img_name+img_format, dpi=dpi, format=\"png\")\n",
    "        print(img_name)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        \n",
    "        # filter picks if the fit did not work properly\n",
    "        #  1. fit did not converge (all parameters == 0)\n",
    "        if all(par == 0 for par in r_par):\n",
    "            filter_passed = \"No\"\n",
    "        #  2. distance between peaks > pick width\n",
    "        elif distance > info[-1]['Pick Width']*pixelsize:\n",
    "            filter_passed = \"No\"\n",
    "        #  3. amplitude of at least one of the peaks is <= 0\n",
    "        elif r_par[0] <= 0 or r_par[3] <= 0:\n",
    "            filter_passed = \"No\"\n",
    "        #  4. sigma of at least one of the peaks is > 30 nm\n",
    "            #sigma_max = 30 # nm\n",
    "        elif r_par[2] > sigma_max or r_par[5] > sigma_max:\n",
    "            filter_passed = \"No\"\n",
    "        #  4. sigma of at least one of the peaks is < 2nm\n",
    "        elif r_par[2] < sigma_min or r_par[5] < sigma_min:\n",
    "            filter_passed = \"No\"\n",
    "        else:\n",
    "            filter_passed = \"Yes\"\n",
    "\n",
    "        if filter_passed == 'No':\n",
    "            shutil.move(os.path.join(analysis_folder, img_fname + img_format), os.path.join(excluded_folder, img_fname + img_format))\n",
    "            shutil.move(os.path.join(analysis_folder, img_zfilter_fname + img_format), os.path.join(excluded_folder, img_zfilter_fname + img_format))\n",
    "\n",
    "        \n",
    "        \n",
    "        arc_data.append([fov_id, #running file index\n",
    "                              cell_type, # veg or spore\n",
    "                              filename, #filename\n",
    "                              pick, #pick number\n",
    "                              r_par[1], # center 1\n",
    "                              r_par[2], # sigma 1\n",
    "                              r_par[0], # aplitude 1\n",
    "                              r_par[4], # center 1\n",
    "                              r_par[5], # sigma 1\n",
    "                              r_par[3], # aplitude 1\n",
    "                              distance, # distance\n",
    "                              filter_passed,\n",
    "                             ])\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    Plot locs\n",
    "    2d gauss fit on histogram\n",
    "    plot 2d Gauss\n",
    "    \"\"\" \n",
    "        \n",
    "        \n",
    "print()\n",
    "print('The following files could not be loaded.')\n",
    "print('Probably they miss the x_pick_rot column:')\n",
    "for filename in files_no_x_pick_rot:\n",
    "    print(' -', filename)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Save arc data\n",
    "df_arc_data_add = pd.DataFrame(arc_data, columns=[\"fov_id\",\n",
    "                                                \"cell_type\",\n",
    "                                                \"filename\",\n",
    "                                                \"group\",\n",
    "                                                \"x_1\",\n",
    "                                                \"sigma_1\",\n",
    "                                                \"amplitude_1\",\n",
    "                                                \"x_2\",\n",
    "                                                \"sigma_2\",\n",
    "                                                \"amplitude_2\",\n",
    "                                                \"distance\",\n",
    "                                                \"filter_passed\"\n",
    "                                               ])\n",
    "if df_arc_data is not None:\n",
    "    df_arc_data_save = pd.concat([df_arc_data, df_arc_data_add], ignore_index = True)\n",
    "else:\n",
    "    df_arc_data_save = df_arc_data_add\n",
    "    \n",
    "df_arc_data_save.to_csv(\"arc_data.csv\")        \n",
    "# Save dataframe with cell means for easy loading of data for postprocessing\n",
    "df_arc_data_save.to_pickle(\"arc_data.pkl\")\n",
    "\n",
    "\n",
    "print(\"Data saved to CSV file in locs folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5970b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb76ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cd60e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
